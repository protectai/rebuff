# Rebuff AI Documentation

Welcome to the Rebuff AI documentation! Rebuff AI is a self-hardening prompt injection detector designed to protect AI applications from prompt injection (PI) attacks through a multi-stage defense.

<figure><img src=".gitbook/assets/mascot.png" alt="" width="150"><figcaption></figcaption></figure>

## Important Notice

> **⚠️ Rebuff AI is currently in an alpha state! Please use it with caution and be aware that it may have limitations and potential bugs.**


## Useful Links

- [Homepage](https://rebuff.ai/): Visit the official Rebuff AI homepage to learn more about the project.
- [GitHub](https://github.com/woop/rebuff): Access the Rebuff AI GitHub repository for the latest source code, issue tracking, and contributions.
- [Playground](https://playground.rebuff.ai/): Try out the Rebuff AI Playground to experiment with the detector and see it in action.

## Table of Contents

- [Quickstart Guide (Python)](quickstart.md): Get started quickly with Rebuff AI using Python and learn the basics.
- [Self-Hosting](self-hosting.md): Learn how to self-host Rebuff AI in your own infrastructure.
- [How It Works](how-it-works.md): Understand the inner workings of Rebuff AI and its multi-stage defense mechanism.

We hope this documentation helps you get started with Rebuff AI and protect your AI applications effectively. If you have any questions or encounter any issues, please refer to the [GitHub repository](https://github.com/woop/rebuff) for support and assistance.
